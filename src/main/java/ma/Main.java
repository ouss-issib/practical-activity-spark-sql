package ma;

import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.functions;

//TIP To <b>Run</b> code, press <shortcut actionId="Run"/> or
// click the <icon src="AllIcons.Actions.Execute"/> icon in the gutter.
public class Main {
    public static void main(String[] args) {

        // CrÃ©er une session Spark
        SparkSession spark = SparkSession.builder()
                .appName("Incident Analyzer")
                .master("local[*]")
                .getOrCreate();

        // Charger le fichier CSV
        Dataset<Row> df = spark.read()
                .option("header", true)
                .option("inferSchema", true)
                .csv("src/main/resources/incidents_random.csv");

        // Afficher le schÃ©ma pour vÃ©rifier
        df.printSchema();

        // 1. Nombre dâ€™incidents par service
        System.out.println("ðŸ”¸ Nombre dâ€™incidents par service :");
        df.groupBy("service")
                .count()
                .orderBy(functions.desc("count"))
                .show();

        // 2. Extraire lâ€™annÃ©e de la colonne "date" et compter par annÃ©e
        Dataset<Row> dfWithYear = df.withColumn("year", functions.year(df.col("date")));

        System.out.println("ðŸ”¸ Deux annÃ©es avec le plus dâ€™incidents :");
        dfWithYear.groupBy("year")
                .count()
                .orderBy(functions.desc("count"))
                .limit(2)
                .show();

        spark.stop();
    }
}